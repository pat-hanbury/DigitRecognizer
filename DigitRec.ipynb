{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-dd0d7c3cd3f2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-dd0d7c3cd3f2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    RESOURCE: https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RESOURCE: https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, Image\n",
    "\n",
    "path = \"data/\"\n",
    "train_path = path + 'train.csv'\n",
    "test_path = path + 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/patrick/projects/digitRec/DigitRecognizer/data/sample_submission.csv\n",
      "/home/patrick/projects/digitRec/DigitRecognizer/data/test.csv\n",
      "/home/patrick/projects/digitRec/DigitRecognizer/data/train.csv\n"
     ]
    }
   ],
   "source": [
    "for x in Path.iterdir(PATH/'data'):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import CSV into pandas dataframe and convert to np array\n",
    "test_data = pd.read_csv(PATH/'data/test.csv')\n",
    "train_data = pd.read_csv(PATH/'data/train.csv')\n",
    "test_np_data = test_data.values;\n",
    "train_np_data = train_data.values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn a row of our data into a square image to be used by matplotlib\n",
    "def getImg(img_in, h, w):\n",
    "    #input is a 1D array (single row in our 2D np array representation of csv file)\n",
    "    img_out = np.zeros(shape=(h,w))\n",
    "    row = 0\n",
    "    for x in range(1,h*w): #sine index 1 is the label\n",
    "        col = x%w\n",
    "        img_out[row][col] = img_in[x]\n",
    "        if col == w-1:\n",
    "            row = row + 1\n",
    "    return img_out\n",
    "            \n",
    "def show_npimg(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def show_im(img, h=28,w=28):\n",
    "    temp = getImg(img, h, w)\n",
    "    show_npimg(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##show a single image\n",
    "show_im(train_np_data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrnValSets(trn,val_split = 0.2):\n",
    "    set_trace()\n",
    "    cutoff = int(val_split*len(trn))\n",
    "    set_trace()\n",
    "    np.random.shuffle(trn)\n",
    "    train, val = trn[:cutoff,:], trn[cutoff:,:]\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-9-76fb6e11ea2f>\u001b[0m(3)\u001b[0;36mgetTrnValSets\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mgetTrnValSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_split\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m<ipython-input-9-76fb6e11ea2f>\u001b[0m(5)\u001b[0;36mgetTrnValSets\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m    \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_split\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "trn_np , val_np = getTrnValSets(train_np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Prepare data in Numpy\n",
    "def get3D(data1D, h=28, w=28):\n",
    "     #input is a 1D array (single row in our 2D np array representation of csv file)\n",
    "     #output is a 3D tensor (channel,height,width)\n",
    "    np_out = np.zeros(shape=(1,h,w))\n",
    "    row = 0\n",
    "    for x in range(1,h*w): #sine index 1 is the label\n",
    "        col = x%w\n",
    "        np_out[0][row][col] = data1D[x]\n",
    "        if col == w-1:\n",
    "            row = row + 1\n",
    "    return np_out\n",
    "\n",
    "def get4D(data2D, h=28, w=28):\n",
    "    #input is 2D array (image number x pixel values)\n",
    "    #output is 4D tensor (image number x channel x h x w)\n",
    "    num_img = len(data2D)\n",
    "    np_out = np.zeros(shape=(num_img, 1, h, w))\n",
    "    for i in range(num_img):\n",
    "        np_out[i] = get3D(data2D[i])\n",
    "    return torch.from_numpy(np_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create Dataset and Dataloader\n",
    "#features needs to be 4D, where each index 0 is the image, index 1 is the channel, and 3/4 are h/w\n",
    "#targets needs to be 1D, where each index represents an image\n",
    "train_features = get4D(trn_np[:,1:])\n",
    "train_targets = torch.from_numpy(trn_np[:,0])\n",
    "trn_data = utils.TensorDataset(train_features, train_targets)\n",
    "train_loader = utils.DataLoader(trn_data,batch_size=64,shuffle=True,num_workers=4)\n",
    "\n",
    "val_features = get4D(val_np[:,1:])\n",
    "val_targets = torch.from_numpy(val_np[:,0])\n",
    "val_data = utils.TensorDataset(val_features, val_targets)\n",
    "val_loader = utils.DataLoader(val_data, batch_size=64,shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BnLayer class from FastAI -- \n",
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=kernel_size, stride=stride,\n",
    "                            bias=False, padding=1)\n",
    "        self.add = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.mult = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        set_trace()\n",
    "        x = F.relu(self.conv(inp))\n",
    "        #don't understand how they are calculating the means\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds = x_chan.std(1)[:None,None]\n",
    "        return (x-self.means)/self.stds * self.mult + self.add\n",
    "    \n",
    "#Resnet Layer from FastAI -- \n",
    "class ResnetLayer(BnLayer):\n",
    "    def forward(self,inp): return inp + super().forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet Model from FastAi --\n",
    "class Resnet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in layers (list)  and c (int, number of classes) as input\n",
    "    \"\"\"\n",
    "    def __init__(self,layers,c):\n",
    "        set_trace()\n",
    "        super(Resnet,self).__init__()\n",
    "        #initial large Conv Layer (applied once)\n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5, stride=1, padding=2)\n",
    "        self.layers1 = nn.ModuleList([BnLayer(layers[i],layers[i+1])\n",
    "            for i in range(len(layers)-1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1],layers[i+1],\n",
    "            stride=1) for i in range(len(layers)-1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1],layers[i+1],\n",
    "            stride=1) for i in range(len(layers)-1)])\n",
    "        self.out = nn.Linear(layers[-1],c)\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        set_trace()\n",
    "        x = self.conv1(inp)\n",
    "        for l1,l2,l3 in zip(self.layers1, self.layers2, self.layers3):\n",
    "            x = l3(l2(l1(x)))\n",
    "        x = F.adaptive_max_pool2d(x,1)\n",
    "        #don't get this\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available?   :   True\n"
     ]
    }
   ],
   "source": [
    "print('Is GPU available?   :   ' + str(torch.cuda.is_available()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-14-0ef33a0d51ab>\u001b[0m(8)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      6 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 8 \u001b[0;31m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m        \u001b[0;31m#initial large Conv Layer (applied once)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "on gpu\n"
     ]
    }
   ],
   "source": [
    "layers = [10, 20, 40]\n",
    "num_classes = 10\n",
    "model=Resnet(layers, num_classes)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print('on gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "wd=0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = Adam(model.parameters(),lr=lr, weight_decay=wd )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###KEY FUNCTIONS FOR TRAINING###\n",
    "\n",
    "#FOO: change this to take in a list of lrs. annd adjust LR\n",
    "#function to get a learning rate while training (using discrimative learning rates)\n",
    "def get_lr_rate(epoch, num_epochs, init_lr=0.001, lr_div=10):\n",
    "    lr = init_lr\n",
    "    if epoch/num_epochs > 0.6:\n",
    "        lr = lr/(lr_div*lr_div)\n",
    "    elif epoch/num_epochs > 0.3:\n",
    "        lr = lr/lr_div\n",
    "    return lr\n",
    "\n",
    "#function for saving models\n",
    "def save_models(m,idx,fn='digit_rec_model_'):\n",
    "    torch.save(m.state_dict(), f\"{fn}{idx}\")\n",
    "    print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Training Function###\n",
    "#def get_trn_loss(m,activations,labels):\n",
    "      \n",
    "\n",
    "#def get_val_acc(model,train):\n",
    "    \n",
    "def get_loss(act,targets):\n",
    "    #computes loss for a given batch of activations (act) and target values (targets)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion(act,targets)\n",
    "    \n",
    "def predict(activs):\n",
    "    _,predictions = torch.max(activs.data,1)\n",
    "    return predictions\n",
    "\n",
    "def train(m,num_epochs,init_lr=0.001):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for param_group in opt.param_groups:\n",
    "        param_group[\"lr\"] = init_lr\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #set model to training mode\n",
    "        acc = 0.0\n",
    "        loss = 0.0\n",
    "        for i, (images,gt) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                #images.cuda()\n",
    "                #gt.cuda()\n",
    "            opt.zero_grad() #zero all gradients\n",
    "            set_trace()\n",
    "            outputs=model(images) #get output activations\n",
    "            loss = get_loss(outputs,gt)\n",
    "            loss.backward() #backprop loss\n",
    "            opt.step() #change parameters\n",
    "            \n",
    "            tot_loss += loss.data[0]\n",
    "            tot_acc += acc\n",
    "            \n",
    "        lr = get_lr_rate(epoch, num_epochs, init_lr)\n",
    "        for param_group in opt.param_groups: \n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        acc = get_val_acc(m)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            save_models(model,epoch)\n",
    "        #show metrics for each epoch\n",
    "        print(\"Epoch: {epoch}   TrnLoss: {loss}   ValAcc: {acc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.autograd.Variable(torch.randn((3,5)))\n",
    "tgt = torch.autograd.Variable(torch.LongTensor(3).random_(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = loss(input,tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a validation set\n",
    "\n",
    "import numpy\n",
    "# x is your dataset\n",
    "x = numpy.random.rand(100, 5)\n",
    "numpy.random.shuffle(x)\n",
    "training, test = x[:80,:], x[80:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
