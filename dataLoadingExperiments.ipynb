{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-dd0d7c3cd3f2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-dd0d7c3cd3f2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    RESOURCE: https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RESOURCE: https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6c7ef91e9580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchvision.data import DataLoader\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, Image\n",
    "\n",
    "path = \"data/\"\n",
    "train_path = path + 'train.csv'\n",
    "test_path = path + 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in Path.iterdir(PATH/'data'):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import CSV into pandas dataframe and convert to np array\n",
    "test_data = pd.read_csv(PATH/'data/test.csv')\n",
    "train_data = pd.read_csv(PATH/'data/train.csv')\n",
    "test_np_data = test_data.values;\n",
    "train_np_data = train_data.values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn a row of our data into a square image to be used by matplotlib\n",
    "def getImg(img_in, h, w):\n",
    "    #input is a 1D array (single row in our 2D np array representation of csv file)\n",
    "    img_out = np.zeros(shape=(h,w))\n",
    "    row = 0\n",
    "    for x in range(1,h*w): #since index 1 is the label\n",
    "        col = x%w\n",
    "        img_out[row][col] = img_in[x]\n",
    "        if col == w-1:\n",
    "            row = row + 1\n",
    "    return img_out\n",
    "            \n",
    "def show_npimg(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def show_im(img, h=28,w=28):\n",
    "    temp = getImg(img, h, w)\n",
    "    show_npimg(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290967fd908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##show a single image\n",
    "show_im(train_np_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-12195a9f9e4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "##create Dataset and Dataloader\n",
    "#features needs to be 2D, where each row represents and Image\n",
    "#targets needs to be 1D, where each index represents an image\n",
    "train_features = torch.from_numpy(train_np_data[:,1:])\n",
    "train_targets = torch.from_numpy(train_np_data[:,0])\n",
    "train_targets.size() , train_features.size()\n",
    "trn_data = utils.TensorDataset(train_features, train_targets)\n",
    "\n",
    "train_loader = Dataloader(trn_data,batchsize=64,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BnLayer class from FastAI -- \n",
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni,nf,kernel_size=kernel_size, stride=stride,\n",
    "                            bias=False, padding=1)\n",
    "        self.add = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.mult = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        x = F.relu(self.conv(inp))\n",
    "        #don't understand how they are calculating the means\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds = x_chan.std(1)[:None,None]\n",
    "        return (x-self.means)/self.stds * self.mult + self.add\n",
    "    \n",
    "#Resnet Layer from FastAI -- \n",
    "class ResnetLayer(BnLayer):\n",
    "    def forward(self,inp): return inp + super().forward(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet Model from FastAi --\n",
    "class Resnet(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes in layers (list)  and c (int, number of classes) as input\n",
    "    \"\"\"\n",
    "    def __init__(self,layers,c):\n",
    "        set_trace()\n",
    "        super(Resnet,self).__init__()\n",
    "        #initial large Conv Layer (applied once)\n",
    "        self.conv1 = nn.Conv2d(3,10,kernel_size=5, stride=1, padding=2)\n",
    "        self.layers1 = nn.ModuleList([BnLayer(layers[i],layers[i+1])\n",
    "            for i in range(len(layers)-1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1],layers[i+1],\n",
    "            stride=1) for i in range(len(layers)-1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1],layers[i+1],\n",
    "            stride=1) for i in range(len(layers)-1)])\n",
    "        self.out = nn.Linear(layers[-1],c)\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        x = self.conv1(inp)\n",
    "        for l1,l2,l3 in zip(self.layers1, self.layers2, self.layers3):\n",
    "            x = l3(l2(l1(x)))\n",
    "        x = F.adaptive_max_pool2d(x,1)\n",
    "        #don't get this\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available?   :   False\n"
     ]
    }
   ],
   "source": [
    "print('Is GPU available?   :   ' + str(torch.cuda.is_available()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-12-7b3c1b2b8dd0>\u001b[0m(8)\u001b[0;36m__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      6 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m        \u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 8 \u001b[1;33m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[1;31m#initial large Conv Layer (applied once)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "layers = [10, 5, 5]\n",
    "num_classes = 10\n",
    "model=Resnet(layers, num_classes)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "wd=0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = Adam(model.parameters(),lr=lr, weight_decay=wd )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###KEY FUNCTIONS FOR TRAINING###\n",
    "\n",
    "#FOO: change this to take in a list of lrs. annd adjust LR\n",
    "#function to get a learning rate while training (using discrimative learning rates)\n",
    "def get_lr_rate(epoch, num_epochs, init_lr=0.001, lr_div=10):\n",
    "    lr = init_lr\n",
    "    if epoch/num_epochs > 0.6:\n",
    "        lr = lr/(lr_div*lr_div)\n",
    "    elif epoch/num_epochs > 0.3:\n",
    "        lr = lr/lr_div\n",
    "    return lr\n",
    "\n",
    "#function for saving models\n",
    "def save_models(m,idx,fn='digit_rec_model_'):\n",
    "    torch.save(m.state_dict(), f\"{fn}{idx}\")\n",
    "    print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Training Function###\n",
    "def get_trn_loss(m,activations,labels):\n",
    "    \n",
    "    \n",
    "def get_val_acc(m,activations,labels):\n",
    "    \n",
    "def predict(activs):\n",
    "    _,predictions = torch.max(activs.data,1)\n",
    "    return predictions\n",
    "\n",
    "def train(m,num_epochs,init_lr):\n",
    "    best_acc = 0.0\n",
    "    for param_group in opt.param_groups:\n",
    "        param_group[\"lr\"] = init_lr\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #set model to training mode\n",
    "        acc = 0.0\n",
    "        loss = 0.0\n",
    "        for i, (images,labels) in enumerate(trn.loader):\n",
    "            if torch.cuda.is_available():\n",
    "                img.cuda()\n",
    "                labels.cuda()\n",
    "            opt.zero_grad() #zero all gradients\n",
    "            outputs=model(images) #get output activations\n",
    "            loss = get_loss(m,outputs,labels) #compute loss\n",
    "            loss.backward() #backprop loss\n",
    "            opt.step() #change parameters\n",
    "            \n",
    "        lr = get_lr_rate(epoch, num_epochs, init_lr)\n",
    "        for param_group in opt.param_groups: \n",
    "            param_group[\"lr\"] = lr\n",
    "            \n",
    "        loss = get_trn_loss(...)\n",
    "        acc = get_val_acc(...)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            save_models(model,epoch)\n",
    "        #show metrics for each epoch\n",
    "        print(\"Epoch: {epoch}   TrnLoss: {loss}   ValAcc: {acc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
